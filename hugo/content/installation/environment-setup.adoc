---
title: "Environment Setup"
date: 2018-05-08T08:52:09-07:00
draft: false
weight: 1
---

:toc:
v2.0, {docdate}

== Requirements

The Crunchy Container Suite can run on different environments including:

 * *Docker 1.12+*
 * *OpenShift Container Platform 3.6+*
 * *Kubernetes 1.8+*

In this document we list the basic installation steps required for these
environments.

These installation instructions are developed and tested for the following operating systems:

 * *CentOS 7*
 * *RHEL 7*

== Project Environment

First add the following lines to your .bashrc file to set
the project paths:
....
export GOPATH=$HOME/cdev
export GOBIN=$GOPATH/bin
export PATH=$PATH:$GOBIN
export CCP_BASEOS=centos7
export CCP_PGVERSION=10
export CCP_PG_FULLVERSION=10.4
export CCP_VERSION=2.0
export CCP_IMAGE_PREFIX=crunchydata
export CCP_IMAGE_TAG=$CCP_BASEOS-$CCP_PG_FULLVERSION-$CCP_VERSION
export CCPROOT=$GOPATH/src/github.com/crunchydata/crunchy-containers
export CCP_SECURITY_CONTEXT=""
export CCP_CLI=kubectl
export CCP_NAMESPACE=demo
....

{{% notice tip %}}
Please see the link:/installation/storage-configuration/[Storage Configuration] document
for configuring storage using environment variables set in .bashrc.

Additionally, the `CCP_CLI` setting above indicates you are running the
examples on a Kubernetes platform and not an OpenShift platform.  For
OpenShift, use the value of *oc* as the `CCP_CLI` variable instead.
{{% /notice %}}

It will be necessary to refresh your `.bashrc` file in order for the changes to take
effect.

....
. ~/.bashrc
....

Next, set up a project directory structure and pull down the project:
....
mkdir -p $HOME/cdev/src $HOME/cdev/pkg $HOME/cdev/bin
....

== Installing Requirements

=== CentOS 7
....
cd $GOPATH
sudo yum -y install golang git docker
go get github.com/tools/godep
cd src/github.com
mkdir crunchydata
cd crunchydata
git clone https://github.com/crunchydata/crunchy-containers
cd crunchy-containers
git checkout 2.0
go get github.com/blang/expenv
....

{{% notice tip %}}
If you are a Crunchy enterprise customer, you will place the Crunchy repository
key and yum repository file into the `$CCPROOT/conf` directory at this point. These
files can be obtained through https://access.crunchydata.com/ on the downloads
page.
{{% /notice %}}

=== RHEL 7

When setting up the environment on RHEL 7, there are slightly different steps that
need to be taken.

....
cd $GOPATH
sudo subscription-manager repos --enable=rhel-7-server-optional-rpms
sudo yum-config-manager --enable rhel-7-server-extras-rpms
sudo yum -y install git golang
go get github.com/tools/godep
cd src/github.com
mkdir crunchydata
cd crunchydata
git clone https://github.com/crunchydata/crunchy-containers
cd crunchy-containers
git checkout 2.0
go get github.com/blang/expenv
....

{{% notice tip %}}
If you are a Crunchy enterprise customer, you will place the Crunchy repository
key and yum repository file into the `$CCPROOT/conf` directory at this point. These
files can be obtained through https://access.crunchydata.com/ on the downloads
page.
{{% /notice %}}

=== PostgreSQL

These installation instructions assume the installation of PostgreSQL 10
through the official PGDG repository. View the documentation located
link:https://wiki.postgresql.org/wiki/YUM_Installation[here] in
order to view more detailed notes or install a different version of PostgreSQL.

Locate and edit your distribution's `.repo` file, located:

 * On CentOS: /etc/yum.repos.d/CentOS-Base.repo, [base] and [updates] sections
 * On Red Hat: /etc/yum/pluginconf.d/rhnplugin.conf [main] section

To the section(s) identified above, you need to append a line (otherwise
dependencies might resolve to the PostgreSQL supplied by the base repository):

....
exclude=postgresql*
....

Next, install the RPM relating to the base operating system and PostgreSQL version
you wish to install. The RPMs can be found link:https://yum.postgresql.org/repopackages.php[here].

For example, to install PostgreSQL 10 on a CentOS 7 system:
....
sudo yum -y install https://download.postgresql.org/pub/repos/yum/10/redhat/rhel-7-x86_64/pgdg-centos10-10-2.noarch.rpm
....

Or to install PostgreSQL 10 on a RHEL 7 system:
....
sudo yum -y install https://download.postgresql.org/pub/repos/yum/testing/10/redhat/rhel-7-x86_64/pgdg-redhat10-10-2.noarch.rpm
....

You'll need to update your system:
....
sudo yum -y update
....

Then, go ahead and install the PostgreSQL server package.
....
sudo yum -y install postgresql10-server.x86_64
....

=== Docker

As good practice, at this point you'll update your system.
....
sudo yum -y update
....

Now we'll install Docker.
....
sudo yum -y install docker
....

After that, it's necessary to add the `docker` group and give your user access
to that group (here referenced as *someuser*):
....
sudo groupadd docker
sudo usermod -a -G docker someuser
....

Remember to log out of the *someuser* account for the Docker group
to be added to your current session.  Once it's added, you'll be able
to run Docker commands from your user account.
....
su - someuser
....

You can ensure your *someuser* account is added correctly by running the following
command and ensuring `docker` appears as one of the results:
....
groups
....

Before you start Docker, you might consider configuring Docker storage:
This is described if you run:
....
man docker-storage-setup
....

Follow the instructions available link:https://docs.openshift.com/container-platform/3.4/install_config/install/host_preparation.html#configuring-docker-storage[on the main OpenShift documentation page]
to configure Docker storage appropriately.

These steps are illustrative of a typical process for setting up Docker storage. You will need to run these commands as root.

First, add an extra virtual hard disk to your virtual machine (see link:http://catlingmindswipe.blogspot.com/2012/02/how-to-create-new-virtual-disks-in.html[this blog post] for tips on how to do so).

Run this command to format the drive, where `/dev/sd?` is the new hard drive that was added:

....
fdisk /dev/sd?
....

Next, create a volume group on the new drive partition within the `fdisk` utility:

....
vgcreate docker-vg /dev/sd?
....

Then, you'll need to edit the `docker-storage-setup` configuration file in order to override default options. Add these two lines to `/etc/sysconfig/docker-storage-setup`:

....
DEVS=/dev/sd?
VG=docker-vg
....

Finally, run the command `docker-storage-setup` to use that new volume group. The results should state that the physical volume `/dev/sd?` and the volume group `docker-vg` have both been successfully created.

Next, we enable and start up Docker:
....
sudo systemctl enable docker.service
sudo systemctl start docker.service
....

Verify that Docker version 1.12.6 was installed, as per the OpenShift 3.6
link:https://docs.openshift.com/container-platform/3.6/install_config/install/host_preparation.html#installing-docker[requirements.]

....
docker version
....

=== OpenShift

See the OpenShift installation guide for details on how to install
OpenShift Enterprise on your host. The main instructions are here:

https://docs.openshift.com/container-platform/3.6/install_config/install/quick_install.html

NOTE: If you install OpenShift Enterprise on a server with less than `16GB` memory and `40GB`
of disk, the following Ansible variables need to be added to `~/.config/openshift/installer.cfg.yml`
prior to installation:

....
openshift_check_min_host_disk_gb: '10' # min 10gb disk
openshift_check_min_host_memory_gb: '3' # min 3gb memory
....

=== Kubernetes

See link:https://kubernetes.io/docs/setup/independent/install-kubeadm/[kubeadm]
for installing the latest version of Kubernetes.

Please see link:https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/[here]
to view the official documentation regarding configuring DNS for your Kubernetes cluster.

Make sure your hostname resolves to a single IP address in your
/etc/hosts file. The NFS examples will not work otherwise and other problems
with installation can occur unless you have a resolving hostname.

You should see a single IP address returned from this command:
....
hostname --ip-address
....

When running the containers in GKE Role Based Account Control will need to be set up. 
....
kubectl create clusterrolebinding cluster-admin-binding \
--clusterrole cluster-admin --user $(gcloud config get-value account)
....

If more than one user will be running on the same kubernetes cluster in GKE, from the above command cluster-admin-binding will need to be unique and is the name that is added to the clusterrolebidings.  The example below will add another user to the clusterrolebinding with a unique value.
....
$ ACCOUNT=$(gcloud info --format='value(config.account)')
$ kubectl create clusterrolebinding <unique>-cluster-admin-binding \
    --clusterrole cluster-admin \
    --user $ACCOUNT

ACCOUNT is just your google gcloud acount login, ie username@google.com
....

=== Helm

Some Kubernetes Helm examples are provided in the following directory as one
option for deploying the Container Suite.

....
$CCPROOT/examples/helm/
....

Once you have your Kubernetes environment configured, it is simple to get
Helm up and running. Please refer to link:https://github.com/kubernetes/helm/blob/master/docs/install.md[this document]
to get Helm installed and configured properly.

== Creating a Demo Namespace

In Kubernetes, a concept called a *namespace* provides the means to separate
created resources or components into individual logically grouped partitions.

It is considered a best practice to have dedicated namespaces for projects in
both testing and production environments.

NOTE: All examples in the Crunchy Container Suite operate within the namespace
defined by the environment variable `$CCP_NAMESPACE`. The instructions below
illustrate how to set up and work within new namespaces or projects in both
Kubernetes and OpenShift.

=== Kubernetes

This section will illustrate how to set up a new Kubernetes namespace called *demo*, and will
then show how to provide permissions to that namespace to allow the Kubernetes examples to run
within that namespace.

First, view currently existing namespaces:
....
$ kubectl get namespace
NAME          STATUS    AGE
default       Active    21d
kube-public   Active    21d
kube-system   Active    21d
....

Then, create a new namespace called *demo*:
....
$ kubectl create -f $CCPROOT/conf/demo-namespace.json
namespace "demo" created
$ kubectl get namespace demo
NAME      STATUS    AGE
demo      Active    7s
....

Then set the namespace as the current location to avoid using the wrong namespace:
....
$ kubectl config set-context $(kubectl config current-context) --namespace=demo
....

We can verify that the namespace was set correctly through the following command:
....
$ kubectl config view | grep namespace:
    namespace: demo
....

=== OpenShift

This section assumes you are first logging into OpenShift as a normal
user such as:
....
oc login -u someuser
....

For our development purposes only, we typically specify the OCP
Authorization policy of `AllowAll` as documented here:

https://docs.openshift.com/container-platform/3.7/install_config/configuring_authentication.html#AllowAllPasswordIdentityProvider

We do not recommend this authentication policy for a production
deployment of OCP.

The next step is to create a *demo* namespace to run the examples within. The
name of this OCP project will be what you supply in the CCP_NAMESPACE
environment variable:
....
$ oc new-project demo --description="Crunchy Containers project" --display-name="Crunchy-Containers"
Now using project "demo" on server "https://127.0.0.1:8443".

$ export CCP_NAMESPACE=demo
....

If we view the list of projects, we can see the new project has been added and is "active".
....
$ oc get projects
NAME        DISPLAY NAME         STATUS
demo        Crunchy-Containers   Active
myproject   My Project           Active
....

If you were on a different project and wanted to switch to the demo project, you would do
so by running the following:
....
$ oc project demo
Now using project "demo" on server "https://127.0.0.1:8443".
....

Finally, you will want to ensure the proper privileges are added to the user in order to
have the ability to create persistent volumes. A command similar to the following can be
used to accomplish this, by adding the cluster-admin role to the *demo* user:
....
oc adm policy add-cluster-role-to-user cluster-admin demo
....

== Next Steps

Next, build or pull the container images as demonstrated in the link:/installation/build-the-containers/[Build the Containers] document.
