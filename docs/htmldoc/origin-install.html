<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="generator" content="AsciiDoc 8.6.8, bootstrap backend 4.5.0">
    <title>Crunchy Containers</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Crunchy Data Solutions, Inc.">
    <!-- AsciiDoc Bootstrap styles -->
    <link rel="stylesheet" type="text/css" id="bootstrapTheme" href="./stylesheets/asciidoc-bootstrap.min.css">
    <!-- Back to top (jquery plugin) -->
    <link rel="stylesheet" type="text/css" href="./stylesheets/ui.totop.css">

    <!--[if (lt IE 9) & (!IEMobile)]>
        <script src="./javascripts/html5shiv.min.js"></script>
        <script src="./javascripts/respond.min.js"></script>
    <![endif]-->

  </head>
  <body id="toc-top">
    <div id="page">


      <div class="jumbotron">
        <div class="container">
          <h1>Crunchy Containers</h1>
        </div>
      </div>

  <div id="content" class="container">

    <div class="row">




        <div class="col-md-9" role="main">
<div class="section">
    <h1 class="page-header" id="origin_installion_instructions_and_advice">1. Origin Installion Instructions and Advice</h1>
<div class="paragraph"><p>The setup and installation of Origin is described below.</p></div>
<h2 id="install_openshift_origin">1.1. Install Openshift Origin</h2>
<div class="paragraph"><p>Binary releases of Openshift Origin are available here:
<a href="https://github.com/openshift/origin/releases">https://github.com/openshift/origin/releases</a></p></div>
<div class="paragraph"><p>Openshift install steps:</p></div>
<div class="ulist"><ul>
<li>
<p>
download the binary release
</p>
</li>
<li>
<p>
untar the release to your local host
</p>
</li>
<li>
<p>
run as follows:
</p>
</li>
</ul></div>
<div class="literalblock">
<div class="content monospaced">
<pre>sudo ./openshift start</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
set the permissions on the admin kubeconfig file to allow changes
</p>
</li>
</ul></div>
<div class="literalblock">
<div class="content monospaced">
<pre>sudo chmod 666 ./openshift.local.config/master/admin.kubeconfig</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
add the following to your bash shell environment to allow
 you access to the openshift admin account:
</p>
</li>
</ul></div>
<div class="literalblock">
<div class="content monospaced">
<pre>export KUBECONFIG="$(pwd)"/openshift.local.config/master/admin.kubeconfig
export CURL_CA_BUNDLE="$(pwd)"/openshift.local.config/master/ca.crt</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
edit the restricted settings, you will need to change the runAsUser type value to RunAsAny to allow the container to
run as the postgres user.
</p>
</li>
</ul></div>
<div class="literalblock">
<div class="content monospaced">
<pre>oc login -u system:admin
oc edit scc restricted --config=./openshift.local.config/master/admin.kubeconfig</pre>
</div></div>
<div class="ulist"><ul>
<li>
<p>
login in as test user and create a project called pgproject
</p>
</li>
</ul></div>
<div class="literalblock">
<div class="content monospaced">
<pre>oc login -u test
oc new-project pgproject</pre>
</div></div>
<div class="paragraph"><p>Openshift starts an internal DNS server when it starts, and it
registers DNS names for each service that you create.  To
refer to this DNS server, you adjust your /etc/resolv.conf
file to include the Openshift DNS server IP as your primary
name server, also you adjust the searchpath if you
dont want to type <em>&lt;<a href="#projectname">[projectname]</a>.svc.cluster.local when
you refer to the various Openshift services you create.  Here
is an example /etc/resolv.conf that uses an Openshift project
name of 'pgproject</em>:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>search pgproject.svc.cluster.local crunchy.lab
nameserver 192.168.122.71
nameserver 192.168.122.1</pre>
</div></div>
<div class="paragraph"><p>This example used an Openshift project name of <em>pgproject</em>.  The
project name is used as part of the DNS names set by Openshift
for Services.</p></div>
<h2 id="origin_prerequisites">1.2. Origin Prerequisites</h2>
<div class="paragraph"><p>NFS is required for some of the Openshift examples, those dealing with
backups and restores will require a working NFS.</p></div>
<div class="paragraph"><p>NFS is able to run in selinux Enforcing mode if you
following the instructions here:</p></div>
<div class="paragraph"><p><a href="https://github.com/openshift/origin/tree/master/examples/wordpress">https://github.com/openshift/origin/tree/master/examples/wordpress</a></p></div>
<div class="paragraph"><p>Other information on how to install and configure an NFS share is located
here:</p></div>
<div class="paragraph"><p><a href="http://www.itzgeek.com/how-tos/linux/centos-how-tos/how-to-setup-nfs-server-on-centos-7-rhel-7-fedora-22.html">http://www.itzgeek.com/how-tos/linux/centos-how-tos/how-to-setup-nfs-server-on-centos-7-rhel-7-fedora-22.html</a></p></div>
<div class="paragraph"><p>Examples of Openshift NFS can be found here:</p></div>
<div class="paragraph"><p><a href="https://github.com/openshift/origin/tree/master/examples/wordpress/nfs">https://github.com/openshift/origin/tree/master/examples/wordpress/nfs</a></p></div>
<div class="paragraph"><p>The examples specify a test NFS server running at IP address 192.168.0.103</p></div>
<div class="paragraph"><p>On that server, the /etc/exports file looks like this:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>/jeffnfs *(rw,sync)</pre>
</div></div>
<div class="paragraph"><p>if you are running your client on a VM, you will need to
add <em>insecure</em> to the exportfs file on the NFS server, this is because
of the way port translation is done between the VM host and the VM instance.</p></div>
<div class="paragraph"><p>see this for more details:</p></div>
<div class="paragraph"><p><a href="http://serverfault.com/questions/107546/mount-nfs-access-denied-by-server-while-mounting">http://serverfault.com/questions/107546/mount-nfs-access-denied-by-server-while-mounting</a></p></div>
</div>
<div class="section">
    <h1 class="page-header" id="origin_tips">2. Origin Tips</h1>
<h2 id="tip_1_finding_the_postgresql_passwords">2.1. Tip 1: Finding the Postgresql Passwords</h2>
<div class="paragraph"><p>The passwords used for the PostgreSQL user accounts are generated
by the Openshift <em>process</em> command.  To inspect what value was
supplied, you can inspect the master pod as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>oc get pod pg-master-rc-1-n5z8r -o json</pre>
</div></div>
<div class="paragraph"><p>Look for the values of the environment variables:</p></div>
<div class="ulist"><ul>
<li>
<p>
PG_USER
</p>
</li>
<li>
<p>
PG_PASSWORD
</p>
</li>
<li>
<p>
PG_DATABASE
</p>
</li>
</ul></div>
<h2 id="tip_2_examining_a_backup_job_log">2.2. Tip 2: Examining a backup job log</h2>
<div class="paragraph"><p>Database backups are implemented as a Kubernetes Job.  A Job is meant to run one time only
and not be restarted by Kubernetes.  To view jobs in Openshift you enter:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>oc get jobs
oc describe job backupjob</pre>
</div></div>
<div class="paragraph"><p>You can get detailed logs by referring to the pod identifier in the job <em>describe</em>
output as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>oc logs backupjob-pxh2o</pre>
</div></div>
<h2 id="tip_3_backup_lifecycle">2.3. Tip 3: Backup Lifecycle</h2>
<div class="paragraph"><p>Backups require the use of network storage like NFS in Openshift.
There is a required order of using NFS volumes in the manner
we do database backups.</p></div>
<div class="paragraph"><p>So, first off, there is a one-to-one relationship between
a PV (persistent volume) and a PVC (persistence volume claim).  You
can NOT have a one-to-many relationship between PV and PVC(s).</p></div>
<div class="paragraph"><p>So, to do a database backup repeatably, you will need to following
this general pattern:
 * as openshift admin user, create a unique PV (e.g. backup-pv-mydatabase)
 * as a project user, create a unique PVC (e.g. backup-pvc-mydatabase)
 * reference the unique PVC within the backup-job template
 * execute the backup job template
 * as a project user, delete the job
 * as a project user, delete the pvc
 * as openshift admin user, delete the unique PV</p></div>
<div class="paragraph"><p>This procedure will need to be scripted and executed by the devops team when
performing a database backup.</p></div>
<h2 id="tip_4_persistent_volume_matching">2.4. Tip 4: Persistent Volume Matching</h2>
<div class="paragraph"><p>Restoring a database from an NFS backup requires the building
of a PV which maps to the NFS backup archive path.  For example,
if you have a backup at /backups/pg-foo/2016-01-29:22:34:20
then we create a PV that maps to that NFS path.  We also use
a "label" on the PV so that the specific backup PV can be identified.</p></div>
<div class="paragraph"><p>We use the pod name in the label value to make the PV unique.  This
way, the related PVC can find the right PV to map to and not some other
PV.  In the PVC, we specify the same "label" which lets Kubernetes
match to the correct PV.</p></div>
<h2 id="tip_5_restore_lifecycle">2.5. Tip 5: Restore Lifecycle</h2>
<div class="paragraph"><p>To perform a database restore, we do the following:
 * locate the NFS path to the database backup we want to restore with
 * edit a PV to use that NFS path
 * edit a PV to specify a unique label
 * create the PV
 * edit a PVC to use the previously created PV, specifying the same label
   used in the PV
 * edit a database template, specifying the PVC to be used for mounting
   to the /backup directory in the database pod
 * create the database pod</p></div>
<div class="paragraph"><p>If the /pgdata directory is blank AND the /backup directory contains
a valid postgres backup, it is assumed the user wants to perform a
database restore.</p></div>
<div class="paragraph"><p>The restore logic will copy /backup files to /pgdata before starting
the database.  It will take time for the copying of the files to
occur since this might be a large amount of data and the volumes
might be on slow networks. You can view the logs of the database pod
to measure the copy progress.</p></div>
<h2 id="tip_6_password_mgmt">2.6. Tip 6: Password Mgmt</h2>
<div class="paragraph"><p>Remember that if you do a database restore, you will get
whatever user IDs and passwords that were saved in the
backup.  So, if you do a restore to a new database
and use generated passwords, the new passwords will
not be the same as the passwords stored in the backup!</p></div>
<div class="paragraph"><p>You have various options to deal with managing your
passwords.</p></div>
<div class="ulist"><ul>
<li>
<p>
externalize your passwords using secrets instead of using generated values
</p>
</li>
<li>
<p>
manually update your passwords to your known values after a restore
</p>
</li>
</ul></div>
<div class="paragraph"><p>Note that you can edit the environment variables when there is a <em>dc</em>
using, currently only the replicas have a <em>dc</em> to avoid the possiblity
of creating multiple masters, this might need to change in the future,
to better support password management:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>oc env dc/pg-master-rc PG_MASTER_PASSWORD=foo PG_MASTER=user1</pre>
</div></div>
<h2 id="tip_7_log_aggregation">2.7. Tip 7: Log Aggregation</h2>
<div class="paragraph"><p>Openshift can be configured to include the EFK stack for log aggregation.
Openshift Administrators can configure the EFK stack as documented
here:</p></div>
<div class="paragraph"><p><a href="https://docs.openshift.com/enterprise/3.1/install_config/aggregate_logging.html">https://docs.openshift.com/enterprise/3.1/install_config/aggregate_logging.html</a></p></div>
<h2 id="tip_8_nss_wrapper">2.8. Tip 8: nss_wrapper</h2>
<div class="paragraph"><p>If an Openshift deployment requires that random generated UIDs be
supported by containers, the Crunchy containers can be modifed
similar to those located here to support the use of nss_wrapper
to equate the random generated UIDs/GIDs by openshift with
the postgres user:</p></div>
<div class="paragraph"><p><a href="https://github.com/openshift/postgresql/blob/master/9.4/root/usr/share/container-scripts/postgresql/common.sh">https://github.com/openshift/postgresql/blob/master/9.4/root/usr/share/container-scripts/postgresql/common.sh</a></p></div>
<h2 id="tip_9_build_box_setup">2.9. Tip 9: build box setup</h2>
<div class="paragraph"><p>golang is required to build the pgbadger container, on RH 7.2, golang
is found in the <em>server optional</em> repository and needs to be enabled
to install.</p></div>
<div class="paragraph"><p>golang is required to build the pgbadger container, on RH 7.2, golang
is found in the <em>server optional</em> repository and needs to be enabled
to install.</p></div>
<h2 id="tip_10_encoding_secrets">2.10. Tip 10: encoding secrets</h2>
<div class="paragraph"><p>You can use kubernetes secrets to set and maintain your database
credentials.  Secrets requires you base64 encode your user and password
values as follows:</p></div>
<div class="literalblock">
<div class="content monospaced">
<pre>echo -n 'myuserid' | base64</pre>
</div></div>
<div class="paragraph"><p>You will paste these values into  your JSON secrets files for values.</p></div>
<h2 id="tip_11_dns_host_entry_and_deploymentconfig">2.11. Tip 11: DNS host entry and DeploymentConfig</h2>
<div class="paragraph"><p>If your openshift environment can not resolve your hostname via
a DNS server (external to openshift!), you will get errors when trying
to create a DeploymentConfig.  So, you can either install dnsmasq
and reconfigure openshift for that, or, you can run a DNS server
on another host and add the openshift host entry to that DNS server.  I
use the skybridge2 Docker container for this purpose.  You have
to remember to adjust your /etc/resolv.conf to specify this new DNS
server.</p></div>
</div>
<div class="section">
    <h1 class="page-header" id="legal_notices">3. Legal Notices</h1>
<div class="paragraph"><p>Copyright © 2017 Crunchy Data Solutions, Inc.</p></div>
<div class="paragraph"><p>CRUNCHY DATA SOLUTIONS, INC. PROVIDES THIS GUIDE "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.</p></div>
<div class="paragraph"><p>Crunchy, Crunchy Data Solutions, Inc. and the Crunchy Hippo Logo are trademarks of Crunchy Data Solutions, Inc.</p></div>
</div>
        </div>  <!-- /.col-md-9 -->
        <div class="col-md-3">
        <div id="sidebar">
    <div class="toc2">
<div class="panel panel-default">
<div class="panel-heading">Table of Contents</div>
<div class="panel-body" id="toc">
</div>
</div>
    </div>
</div>
        </div>  <!-- /.col-md-3 -->
    </div>  <!-- /.row -->

  </div>  <!-- /.container -->

    <footer id="footer" role="contentinfo">
        <div class="container">
<div class="row"><div id="footnotes"></div></div>
        <table>
        <tr>
        <td><b>Crunchy Data Solutions, Inc.</b></td>
        <td>v1.0.3</td>
        <td>February 27, 2016</td>
        </tr>
        </table>
        </div>
    </footer>

    <script src="./javascripts/jquery.min.js"></script>
    <script src="./bootstrap/js/bootstrap.min.js"></script>
    <script src="./javascripts/asciidoc.js"></script>
    <!-- Install TOC and/or footnotes (if necessary) -->
    <script type="text/javascript">asciidoc.install(2);</script>

    <script src="./javascripts/jquery.ui.totop.min.js"></script>



    <!-- Remove footnotes if empty block -->
    <script type="text/javascript">$(function(){ if ($("#footnotes div").length == 0) $("#footnotes").parent().remove(); });</script>

    <script type="text/javascript">$(function(){ if ($("#dropdown-menu-versions")) $("#dropdown-menu-versions").parent().remove(); });</script>

    <script type="text/javascript">$(function(){ $().UItoTop(); });</script>
    </div> <!-- page -->
  </body>
</html>
